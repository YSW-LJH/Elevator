{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "from statsmodels.stats.stattools import robust_kurtosis\n",
    "import statsmodels.tsa.api as smt\n",
    "#导入熵,最大峰值,和零跨率\n",
    "from scipy.stats import entropy\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./01-28/test_raw.xlsx\n"
     ]
    }
   ],
   "source": [
    "# 输入文件: train_raw.xlsx, test_raw.xlsx\n",
    "# 输出文件: 序列文件 特征文件\n",
    "\n",
    "# 文件夹名称\n",
    "dirName = './01-28/'\n",
    "\n",
    "BOTTOMFLOOR = 1\n",
    "TOPFLOOR = 35\n",
    "# # 训练集文件地址\n",
    "# # 训练集原始文件，导出序列文件，导出特征文件\n",
    "doc_file = dirName + 'train_raw.xlsx'\n",
    "seqName = dirName + 'train_sequence'\n",
    "outputName  =dirName + 'train_output.xlsx'\n",
    "\n",
    "# 测试集文件地址\n",
    "# 测试集原始文件，导出序列文件，导出特征文件\n",
    "\n",
    "# # 竹韵数据\n",
    "BOTTOMFLOOR = 1\n",
    "TOPFLOOR = 35\n",
    "doc_file = dirName + 'test_raw.xlsx'\n",
    "# seqName = dirName + 'test_sequence'\n",
    "# outputName = dirName + 'test_output.xlsx'\n",
    "\n",
    "seqName = dirName + 'test_sequence'\n",
    "outputName = dirName + 'test_output.xlsx'\n",
    "\n",
    "# 新时达数据\n",
    "# BOTTOMFLOOR = 1\n",
    "# TOPFLOOR = 4\n",
    "# doc_file = dirName + '新时达数据.xlsx'\n",
    "# seqName = dirName + 'test_sequence'\n",
    "# outputName = dirName + 'test_output.xlsx'\n",
    "\n",
    "# seqName = dirName + 'train_sequence'\n",
    "# outputName  =dirName + 'train_output.xlsx'\n",
    "\n",
    "# # 广州红树湾\n",
    "# BOTTOMFLOOR = 1\n",
    "# TOPFLOOR = 3\n",
    "# doc_file = dirName + '广州红树湾.xlsx'\n",
    "# seqName = dirName + 'test_sequence'\n",
    "# outputName = dirName + 'test_output.xlsx'\n",
    "\n",
    "# 广日默纳克\n",
    "# BOTTOMFLOOR = 1\n",
    "# TOPFLOOR = 4\n",
    "# doc_file = dirName + '广日默纳克.xlsx'\n",
    "# seqName = dirName + 'test_sequence'\n",
    "# outputName = dirName + 'test_output.xlsx'\n",
    "\n",
    "# # 西城花园\n",
    "# BOTTOMFLOOR = 1\n",
    "# TOPFLOOR = 7\n",
    "# doc_file = dirName + '西城花园.xlsx'\n",
    "# seqName = dirName + 'test_sequence'\n",
    "# outputName = dirName + 'test_output.xlsx'\n",
    "\n",
    "# # 广日新时达\n",
    "# BOTTOMFLOOR = 1\n",
    "# TOPFLOOR = 23\n",
    "# doc_file = dirName + '广日新时达.xlsx'\n",
    "# seqName = dirName + 'test_sequence'\n",
    "# outputName = dirName + 'test_output.xlsx'\n",
    "\n",
    "# 实验室默纳克\n",
    "# BOTTOMFLOOR = 1\n",
    "# TOPFLOOR = 4\n",
    "# doc_file = dirName + '实验室默纳克.xlsx'\n",
    "# seqName = dirName + 'test_sequence'\n",
    "# outputName = dirName + 'test_output.xlsx'\n",
    "\n",
    "\n",
    "# 读取原始文件的所有sheet信息\n",
    "excel = openpyxl.load_workbook(doc_file)\n",
    "# 文件的sheet名字\n",
    "sheet_name = excel.sheetnames\n",
    "# 文件的sheet数\n",
    "sheet_num = len(sheet_name)\n",
    "# 储存每个sheet的数据\n",
    "sheet_list =[]\n",
    "print(doc_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 筛选信息列(D0~D8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取文件\n",
    "data_raw = pd.read_excel(doc_file,sheet_name=sheet_name,dtype='str')\n",
    "# 筛选的列名\n",
    "col_name = ['D0','D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8']\n",
    "for name in sheet_name:\n",
    "    # 筛选出的表格重新储存到data_raw\n",
    "    data_raw[name] = data_raw[name][col_name]\n",
    "    # 将原本的 COB-ID 或 ID 更换为 D0\n",
    "    data_raw[name].rename(columns = {'ID':'D0'},inplace = True)\n",
    "    data_raw[name].rename(columns = {'COB-ID':'D0'},inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调整数据结构"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取序列"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 所需函数\n",
    "1. hexToDec 进制转换 16->10\n",
    "2. filterID 筛选ID组合 [筛选列,数据列]\n",
    "3. parseID  构造新ID和序列Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hexToDec 字节从16进制转到10进制\n",
    "def hexToDec(sheet):\n",
    "    # 表格中缺省值填充为 -1\n",
    "    sheet.fillna('-1',inplace = True)\n",
    "    # 对每一列进行进制转换\n",
    "    for col in sheet.columns:\n",
    "        sheet[col] = [int(item,16) for item in sheet[col]]\n",
    "    return sheet\n",
    "\n",
    "# filterID 筛选ID组合\n",
    "def filterID(columns,startIdx = 0,endIdx = None):\n",
    "    '''\n",
    "    输入: [D0,D1,D2,....D8]\n",
    "    输出: [[筛选列,数据列]...]\n",
    "    例如：[\n",
    "            [[D0],D1],\n",
    "            ...\n",
    "            [[D0,D1],D2],\n",
    "            ...\n",
    "            [[D4],D7],\n",
    "            ...\n",
    "        ]\n",
    "    startIdx: 从第几项开始筛选，默认第0项\n",
    "    endIdx:只取 [startIdx ~ i]列作为开头第一列筛选 \n",
    "    [D0..] [D1..]... [Di..] \n",
    "    [Di+1..] 开始不再输出\n",
    "    默认将所有列都筛选\n",
    "    '''\n",
    "    if(endIdx == None): \n",
    "        print(\"默认筛选所有列\")\n",
    "        endIdx = len(columns-1)\n",
    "    # columns 格式转换：Index->list\n",
    "    columns = list(columns)\n",
    "    out = []\n",
    "    # preCols 筛选列\n",
    "    # dataIdx 数据列序号\n",
    "    def parse(preCols,dataIdx):\n",
    "        # 特定列为第一项筛选时结束\n",
    "        if(len(preCols)>0 and columns.index(preCols[0])>=endIdx):return\n",
    "        # 选数据列\n",
    "        for col in columns[dataIdx:]:\n",
    "            if(len(preCols)): out.append([preCols,col])\n",
    "            # 数据列加入筛选列，进行下一次筛选\n",
    "            parse(preCols+[col],columns.index(col)+1)\n",
    "    parse([],startIdx)\n",
    "    return out\n",
    "\n",
    "# parseID\n",
    "def parseID(sheet):\n",
    "    # 返回 新ID和序列的dataframe\n",
    "    sheet_df = pd.DataFrame()\n",
    "    # 储存新ID与序列\n",
    "    newIDs = []\n",
    "    sequences =[] \n",
    "    # 进制转换\n",
    "    sheet = hexToDec(sheet)\n",
    "    # 筛选ID组合\n",
    "    filterCols = filterID(sheet.columns,endIdx=4)\n",
    "\n",
    "    #根据筛选ID组合筛选内容\n",
    "    for filterCol,dataCol in filterCols:\n",
    "        # rname: filterCol 筛选列中的数据\n",
    "        # group: 在 rname 筛选下的表格\n",
    "        for rname,group in sheet.groupby(filterCol):\n",
    "            # 统一rname为列表\n",
    "            if(type(rname)==int):rname = [rname]\n",
    "            else:rname = list(rname)\n",
    "            # 构造新ID和保存序列\n",
    "            newID = ''.join([preItem + str(dataItem) + '_' for preItem,dataItem in zip(filterCol,rname)])+dataCol\n",
    "            sequence = list(group[dataCol])\n",
    "            newIDs.append(newID)\n",
    "            sequences.append(sequence)\n",
    "    \n",
    "    sheet_df['ID'] = newIDs\n",
    "    sheet_df['Sequence'] = sequences\n",
    "    # sheet_df.set_index('ID',inplace=True)\n",
    "    return sheet_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 组装数据"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 单列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "for name in sheet_name:\n",
    "    data = pd.concat([data,parseID(data_raw[name])])\n",
    "# 拼接后重置index，使之保持正确\n",
    "data.reset_index(drop = True,inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 差分序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "添加差分后data形状： (201524, 3)\n"
     ]
    }
   ],
   "source": [
    "differences = []\n",
    "for sequence in data['Sequence']:\n",
    "    differences.append(np.diff(sequence))\n",
    "data['Difference'] = differences\n",
    "print('添加差分后data形状：',data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 删除冗余数据"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 无意义数据\n",
    "1. 重复数据\n",
    "2. 序列长度小于等于2\n",
    "3. 序列方差小于0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "删除不变数据192136条。\n",
      "删除不变数据后data形状： (9388, 3)\n"
     ]
    }
   ],
   "source": [
    "drop_index = []\n",
    "for i,sequence in enumerate(data['Difference']):\n",
    "    if(len(set(sequence))<1):\n",
    "        drop_index.append(i)\n",
    "for i,sequence in enumerate(data['Sequence']):\n",
    "    if(len(set(sequence))==1\n",
    "    or len(sequence)<=2\n",
    "    or np.var(np.array(sequence))<0.1):\n",
    "        drop_index.append(i)\n",
    "# 删除特定行\n",
    "data.drop(drop_index,inplace = True)\n",
    "# 保持index顺序正确\n",
    "data.reset_index(drop = True,inplace=True)\n",
    "print(f\"删除不变数据{len(set(drop_index))}条。\")\n",
    "print('删除不变数据后data形状：',data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 循环数据\n",
    "使用算法：\n",
    "https://writings.sh/post/algorithm-repeated-string-pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "删除循环数据306条。\n",
      "删除循环数据后data形状： (9082, 3)\n"
     ]
    }
   ],
   "source": [
    "cycle_index = []\n",
    "for i,sequence in enumerate(data['Sequence']):\n",
    "    flag = 0\n",
    "    doubleSeq = sequence[1:]+sequence[:-1]\n",
    "    for idx in range(0,len(doubleSeq)-len(sequence)):\n",
    "        if(sequence == doubleSeq[idx:idx+len(sequence)]):\n",
    "            flag = 1\n",
    "            break\n",
    "    if(flag): cycle_index.append(i)\n",
    "# 删除特定行\n",
    "data.drop(cycle_index,inplace = True)\n",
    "# 保持index顺序正确\n",
    "data.reset_index(drop = True,inplace=True)\n",
    "print(f\"删除循环数据{len(cycle_index)}条。\")\n",
    "print('删除循环数据后data形状：',data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征工程\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 序列特征\n",
    "\n",
    "序列重复项去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "depublication = []\n",
    "for sequence in data['Sequence']:\n",
    "    tmpSeq = [sequence[i] for i in range(len(sequence))\n",
    "     if sequence[i-1]!=sequence[i] or i==0]\n",
    "    depublication.append(tmpSeq)\n",
    "data['Depublication'] = depublication"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 范围归一化\n",
    "\n",
    "将楼层范围信号值归到[0,1]\n",
    "\n",
    "楼层范围以下信号<0，楼层范围以上信号>1\n",
    "\n",
    "为避免出现负数，归一化对数据平移，实际楼层信号标准化到[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.470588235294118 -0.029411764705882353\n"
     ]
    }
   ],
   "source": [
    "maxSignal = (255 - BOTTOMFLOOR)/(TOPFLOOR-BOTTOMFLOOR)\n",
    "minSignal = (0 - BOTTOMFLOOR)/(TOPFLOOR-BOTTOMFLOOR)\n",
    "print(maxSignal,minSignal)\n",
    "# 范围归一的dataframe\n",
    "data_nomolized = data.copy(deep=True)\n",
    "# 将两列范围归一化\n",
    "for col in ['Sequence','Depublication']:\n",
    "    for index,sequence in enumerate(data_nomolized[col]):\n",
    "        data_nomolized[col][index] = [(x - BOTTOMFLOOR)/(TOPFLOOR-BOTTOMFLOOR)+1 for x in sequence]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分箱\n",
    "\n",
    "3个箱：小于楼层范围占比，楼层范围占比，大于楼层占比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.array([minSignal-1,-0.001,1,maxSignal])+1\n",
    "sequence_bins = pd.DataFrame()\n",
    "for i in range(data_nomolized.shape[0]):\n",
    "    index = data_nomolized['Sequence'][i]\n",
    "    sequence_bin = pd.Series(index).value_counts(bins=bins,sort=False)\n",
    "    sequence_bins = sequence_bins.append(pd.Series(sequence_bin.values)/len(index),ignore_index=True)\n",
    "# 重命名列名\n",
    "sequence_bins.columns = [f'bin_{i}' for i in range(len(bins)-1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数字特征\n",
    "\n",
    "1. 最大值\n",
    "\n",
    "2. 最小值\n",
    "\n",
    "3. 最左值\n",
    "\n",
    "4. 最右值\n",
    "\n",
    "5. 左小 判断最小值是否为最左值\n",
    "\n",
    "6. 右大 判断最大值是否为最右值\n",
    "\n",
    "7. 平均值\n",
    "\n",
    "8. 最小二乘回归斜率\n",
    "\n",
    "9. 最小二乘回归截距\n",
    "\n",
    "10. 方差\n",
    "\n",
    "11. 曲率\n",
    "\n",
    "12. 求和\n",
    "\n",
    "13. 下4分位数，中位数，上4分位数\n",
    "\n",
    "14. 序列长与楼层范围占比\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feature = pd.DataFrame()\n",
    "data_feature['ID'] = data['ID']\n",
    "# for col in ['Sequence','Depublication']:\n",
    "for col in ['Depublication']:\n",
    "    # 最大值\n",
    "    maxs = []\n",
    "    # 最小值\n",
    "    mins = []\n",
    "    # 最左值\n",
    "    lefts = []\n",
    "    # 最右值\n",
    "    rights = []\n",
    "    # 左小\n",
    "    leftmin = []\n",
    "    # 右大\n",
    "    rightmax = []\n",
    "    # 平均值\n",
    "    averages = []\n",
    "    # 最小二乘回归斜率\n",
    "    slopes = []\n",
    "    # 最小二乘回归截距\n",
    "    intercepts = []\n",
    "    # 方差\n",
    "    vars = []\n",
    "    # 曲率\n",
    "    curvatures = []\n",
    "    # 求和\n",
    "    sums = []\n",
    "    # 下4分位数，中位数，上4分位数\n",
    "    aa = []\n",
    "    bb = []\n",
    "    cc = []\n",
    "    # 序列长与楼层范围占比\n",
    "    lengthSlope = []\n",
    "    \n",
    "    for i,index in enumerate(data_nomolized[col]):\n",
    "        # 计算斜率与截距\n",
    "        slope, intercept = np.polyfit(range(len(index)), index, 1)\n",
    "        diffsum = np.sum(np.diff(index,1))\n",
    "        diff = np.diff(index,1)\n",
    "        a,b,c = np.percentile(diff, (25, 50, 75), interpolation='midpoint')\n",
    "        \n",
    "        maxs.append(np.max(index))\n",
    "        mins.append(np.min(index))\n",
    "        lefts.append(index[0])\n",
    "        rights.append(index[-1])\n",
    "        if(maxs[-1] == rights[-1]):\n",
    "            rightmax.append(1)\n",
    "        else:\n",
    "            rightmax.append(0)\n",
    "        if(mins[-1] == lefts[-1]):\n",
    "            leftmin.append(1)\n",
    "        else:\n",
    "            leftmin.append(0)\n",
    "        averages.append(np.average(index))\n",
    "        slopes.append(slope)\n",
    "        intercepts.append(intercept)\n",
    "        vars.append(np.var(index))\n",
    "        aa.append(a)\n",
    "        bb.append(b)\n",
    "        cc.append(c)\n",
    "        curvatures.append(np.average(np.diff(index,1)))\n",
    "        lengthSlope.append(len(index)/len(range(BOTTOMFLOOR,TOPFLOOR)))\n",
    "    data_feature[col[:3]+'-max'] = maxs\n",
    "    data_feature[col[:3]+'-min'] = mins\n",
    "    data_feature[col[:3]+'-left'] = lefts\n",
    "    data_feature[col[:3]+'-right'] = rights\n",
    "    data_feature[col[:3]+'-leftmin'] = leftmin\n",
    "    data_feature[col[:3]+'-rightmax'] = rightmax\n",
    "    data_feature[col[:3]+'-average'] = averages\n",
    "    data_feature[col[:3]+'-a'] = aa\n",
    "    data_feature[col[:3]+'-b'] = bb\n",
    "    data_feature[col[:3]+'-c'] = cc\n",
    "    data_feature[col[:3]+'-slope'] = slopes\n",
    "    data_feature[col[:3]+'-intercept'] = intercepts\n",
    "    data_feature[col[:3]+'-vars'] = vars\n",
    "    data_feature[col[:3]+'-curvature'] = curvatures\n",
    "    data_feature[col[:3]+'-lenSlope'] = lengthSlope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加上分箱结果列\n",
    "data_feature = pd.concat([data_feature,sequence_bins],axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置训练集label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 楼层位置\n",
    "# 竹韵标签\n",
    "floorID = ['D01856_D129_D20_D371_D5','D01856_D129_D371_D5','D01856_D20_D371_D5',\n",
    "       'D01856_D371_D5','D01856_D129_D20_D371_D5','D01856_D129_D371_D5',\n",
    "       'D01856_D20_D371_D5','D01856_D371_D5','D01856_D129_D20_D371_D5',\n",
    "       'D01856_D129_D371_D5','D01856_D20_D371_D5','D01856_D371_D5',\n",
    "       'D01856_D129_D20_D371_D5','D01856_D129_D371_D5','D01856_D20_D371_D5',\n",
    "       'D01856_D371_D5']\n",
    "# 新时达标签\n",
    "# floorID = [\"D08_D10_D21_D3\",\"D08_D10_D21_D42_D50_D6\",\"D08_D10_D21_D42_D6\",\"D08_D10_D21_D50_D6\",\"D08_D10_D21_D6\",\"D08_D10_D2134_D30_D40_D50_D6\",\"D08_D10_D2134_D30_D40_D6\",\"D08_D10_D2134_D30_D50_D6\",\"D08_D10_D2134_D30_D6\",\"D08_D10_D2134_D40_D50_D6\",\"D08_D10_D2134_D40_D6\",\"D08_D10_D2134_D50_D6\",\"D08_D10_D2134_D6\",\"D08_D10_D2188_D3\",\"D08_D10_D42_D50_D6\",\"D08_D10_D42_D6\",\"D08_D14_D210_D34_D40_D50_D61_D7\",\"D08_D14_D210_D34_D40_D50_D7\",\"D08_D14_D210_D34_D40_D61_D7\",\"D08_D14_D210_D34_D40_D7\",\"D08_D14_D210_D34_D50_D61_D7\",\"D08_D14_D210_D34_D50_D7\",\"D08_D14_D210_D34_D61_D7\",\"D08_D14_D210_D34_D7\",\"D08_D14_D210_D40_D50_D61_D7\",\"D08_D14_D210_D40_D50_D7\",\"D08_D14_D210_D40_D61_D7\",\"D08_D14_D210_D40_D7\",\"D08_D14_D210_D50_D61_D7\",\"D08_D14_D210_D50_D7\",\"D08_D14_D210_D61_D7\",\"D08_D14_D210_D7\",\"D08_D14_D34_D40_D50_D61_D7\",\"D08_D14_D34_D40_D50_D7\",\"D08_D14_D34_D40_D61_D7\",\"D08_D14_D34_D40_D7\",\"D08_D14_D34_D50_D61_D7\",\"D08_D14_D34_D50_D7\",\"D08_D14_D34_D61_D7\",\"D08_D14_D34_D7\",\"D08_D14_D40_D50_D61_D7\",\"D08_D14_D40_D61_D7\",\"D08_D14_D50_D61_D7\",\"D08_D14_D61_D7\",\"D08_D21_D3\",\"D08_D21_D42_D50_D6\",\"D08_D21_D42_D6\",\"D08_D21_D50_D6\",\"D08_D21_D6\",\"D08_D210_D34_D40_D50_D61_D7\",\"D08_D210_D34_D40_D50_D7\",\"D08_D210_D34_D40_D61_D7\",\"D08_D210_D34_D40_D7\",\"D08_D210_D34_D50_D61_D7\",\"D08_D210_D34_D50_D7\",\"D08_D210_D34_D61_D7\",\"D08_D210_D34_D7\",\"D08_D210_D40_D50_D61_D7\",\"D08_D210_D40_D61_D7\",\"D08_D210_D50_D61_D7\",\"D08_D210_D61_D7\",\"D08_D2134_D30_D40_D50_D6\",\"D08_D2134_D30_D40_D6\",\"D08_D2134_D30_D50_D6\",\"D08_D2134_D30_D6\",\"D08_D2134_D40_D50_D6\",\"D08_D2134_D40_D6\",\"D08_D2134_D50_D6\",\"D08_D2134_D6\",\"D08_D2188_D3\",\"D08_D34_D40_D50_D61_D7\",\"D08_D34_D40_D61_D7\",\"D08_D34_D50_D61_D7\",\"D08_D34_D61_D7\",\"D08_D42_D50_D6\",\"D08_D42_D6\",\"D10_D21_D3\",\"D10_D21_D42_D50_D6\",\"D10_D21_D42_D6\",\"D10_D21_D50_D6\",\"D10_D21_D6\",\"D10_D2134_D30_D40_D50_D6\",\"D10_D2134_D30_D40_D6\",\"D10_D2134_D30_D50_D6\",\"D10_D2134_D30_D6\",\"D10_D2134_D40_D50_D6\",\"D10_D2134_D40_D6\",\"D10_D2134_D50_D6\",\"D10_D2134_D6\",\"D10_D2171_D3\",\"D10_D2188_D3\",\"D10_D42_D50_D6\",\"D10_D42_D6\",\"D14_D210_D34_D40_D50_D61_D7\",\"D14_D210_D34_D40_D50_D7\",\"D14_D210_D34_D40_D61_D7\",\"D14_D210_D34_D40_D7\",\"D14_D210_D34_D50_D61_D7\",\"D14_D210_D34_D50_D7\",\"D14_D210_D34_D61_D7\",\"D14_D210_D34_D7\",\"D14_D210_D40_D50_D61_D7\",\"D14_D210_D40_D50_D7\",\"D14_D210_D40_D61_D7\",\"D14_D210_D40_D7\",\"D14_D210_D50_D61_D7\",\"D14_D210_D50_D7\",\"D14_D210_D61_D7\",\"D14_D210_D7\",\"D14_D34_D40_D50_D61_D7\",\"D14_D34_D40_D50_D7\",\"D14_D34_D40_D61_D7\",\"D14_D34_D40_D7\",\"D14_D34_D50_D61_D7\",\"D14_D34_D50_D7\",\"D14_D34_D61_D7\",\"D14_D34_D7\",\"D14_D40_D50_D61_D7\",\"D14_D40_D61_D7\",\"D14_D50_D61_D7\",\"D14_D61_D7\",\"D21_D3\",\"D21_D42_D50_D6\",\"D21_D42_D6\",\"D21_D50_D6\",\"D21_D6\",\"D210_D34_D40_D50_D61_D7\",\"D210_D34_D40_D50_D7\",\"D210_D34_D40_D61_D7\",\"D210_D34_D40_D7\",\"D210_D34_D50_D61_D7\",\"D210_D34_D50_D7\",\"D210_D34_D61_D7\",\"D210_D34_D7\",\"D210_D40_D50_D61_D7\",\"D210_D40_D61_D7\",\"D210_D50_D61_D7\",\"D210_D61_D7\",\"D2134_D30_D40_D50_D6\",\"D2134_D30_D40_D6\",\"D2134_D30_D50_D6\",\"D2134_D30_D6\",\"D2134_D40_D50_D6\",\"D2134_D40_D6\",\"D2134_D50_D6\",\"D2134_D6\",\"D2171_D3\",\"D2188_D3\",\"D34_D40_D50_D61_D7\",\"D34_D40_D61_D7\",\"D34_D50_D61_D7\",\"D34_D61_D7\"]\n",
    "\n",
    "\n",
    "data_feature['Label'] = np.zeros((data_feature.shape[0],1))\n",
    "data_feature['Label'][data_feature.loc[data_feature['ID'].isin(floorID)].index] = 1\n",
    "# data_feature['Label'][data_feature.loc[data_feature['ID'].isin(updownID)].index] = 2\n",
    "# data_feature['Label'][data_feature.loc[data_feature['ID'].isin(doorID)].index] = 3\n",
    "# data_feature['Label'][data_feature.loc[data_feature['ID'].isin(openID)].index] = 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征处理结束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加上bins列\n",
    "data = pd.concat([data,sequence_bins],axis=1)\n",
    "data['Label'] = data_feature['Label']\n",
    "data.to_pickle(seqName+'.pkl')\n",
    "data.to_excel(seqName+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feature.to_excel(outputName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a646819b1e5f23fa9208cf4a3878500e52f6d3eff1f8f50f8160de79116add4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
